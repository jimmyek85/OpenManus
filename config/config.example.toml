# Global LLM configuration
[llm]
model = "deepseek-r1:14b"
base_url = "http://localhost:11434/v1"
api_key = "sk-..."
max_tokens = 4096
temperature = 0.0

# Optional configuration for specific LLM models
[llm.vision]
model = "minicpm-v:latest"
base_url = "http://localhost:11434/v1"
api_key = "sk-..."
